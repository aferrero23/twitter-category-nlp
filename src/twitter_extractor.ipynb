{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: add to the requirements.txt\n",
    "\n",
    "!pip install tweepy==3.10.0 \n",
    "\n",
    "!pip install requests \n",
    "\n",
    "!pip install twython==3.9.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from twython import Twython, TwythonError, TwythonRateLimitError\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../bearer_token.txt\") as tokens:\n",
    "    tokens_json = json.loads(tokens.read())\n",
    "    #os.environ['BEARER_TOKEN'] = token.read()[:-1]\n",
    "    os.environ['CONSUMER_KEY'] = tokens_json['consumer_key']\n",
    "    os.environ['CONSUMER_SECRET'] = tokens_json['consumer_secret']\n",
    "    os.environ['ACESS_TOKEN'] = tokens_json['access_token']\n",
    "    os.environ['ACESS_TOKEN_SECRET'] = tokens_json['access_token_secret']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_key = os.environ.get(\"CONSUMER_KEY\")\n",
    "consumer_secret = os.environ.get(\"CONSUMER_SECRET\")\n",
    "access_token = os.environ.get(\"ACCESS_TOKEN\")\n",
    "access_token_secret = os.environ.get(\"ACCESS_TOKEN_SECRET\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter = Twython(consumer_key, consumer_secret, access_token, access_token_secret) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timeline(user_id, max_id=None):\n",
    "#       \"\"\" \n",
    "#   Loop over a user's timeline, starting at max_id. \n",
    "#   Generator.\n",
    "#  \n",
    "#   We can get up to 15 pages. \n",
    "#   This function loops up to 16 times to make the base case \n",
    "#   `len(tweets) == 0` trigger.\n",
    "#   \"\"\"\n",
    "    for i in range(16):\n",
    "        tweets = twitter.get_user_timeline(screen_name=user_id,\n",
    "                                      max_id=max_id,\n",
    "                                      count=200,\n",
    "                                      trim_user=True,\n",
    "                                      exclude_replies=True,\n",
    "                                      include_rts=False,\n",
    "                                      tweet_mode='extended',)\n",
    "        if len(tweets) > 0:  # last page should have zero results\n",
    "            for tweet in tweets:\n",
    "                max_id = tweet['id'] - 1\n",
    "                yield tweet\n",
    "        else:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "def sleep_until(ts):\n",
    " # \"\"\" Sleep until the given UTC UNIX TIMESTAMP. \"\"\"\n",
    "    next_time = datetime.utcfromtimestamp(int(ts))\n",
    "    now = datetime.utcnow()\n",
    "    offset = (next_time - now).seconds\n",
    "    print(\"Enhancing calm. Next try: {} (Currently {})\".format(next_time, now))\n",
    "    print(\"Sleeping for {}...\".format(offset))\n",
    "    time.sleep(offset)\n",
    "    print(\"Continuing...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Member of Congress</th>\n",
       "      <th>Name</th>\n",
       "      <th>Party</th>\n",
       "      <th>Twitter</th>\n",
       "      <th>Instagram</th>\n",
       "      <th>Facebook</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>North Carolina 12th District</td>\n",
       "      <td>U.S. Representative</td>\n",
       "      <td>Adams, Alma</td>\n",
       "      <td>D</td>\n",
       "      <td>@RepAdams</td>\n",
       "      <td>@repadams</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alabama 4th District</td>\n",
       "      <td>U.S. Representative</td>\n",
       "      <td>Aderholt, Robert</td>\n",
       "      <td>R</td>\n",
       "      <td>@Robert_Aderholt</td>\n",
       "      <td>@robert_aderholt</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>California 31st District</td>\n",
       "      <td>U.S. Representative</td>\n",
       "      <td>Aguilar, Pete</td>\n",
       "      <td>D</td>\n",
       "      <td>@RepPeteAguilar</td>\n",
       "      <td>@rep.peteaguilar</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Georgia 12th District</td>\n",
       "      <td>U.S. Representative</td>\n",
       "      <td>Allen, Rick</td>\n",
       "      <td>R</td>\n",
       "      <td>@RepRickAllen</td>\n",
       "      <td>@rep_rickallen</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Texas 32nd District</td>\n",
       "      <td>U.S. Representative</td>\n",
       "      <td>Allred, Colin</td>\n",
       "      <td>D</td>\n",
       "      <td>@RepColinAllred</td>\n",
       "      <td>@repcolinallred</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>Oregon</td>\n",
       "      <td>U.S. Senator</td>\n",
       "      <td>Wyden, Ron</td>\n",
       "      <td>D</td>\n",
       "      <td>@RonWyden</td>\n",
       "      <td>@ronwyden</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537</th>\n",
       "      <td>Kentucky 3rd District</td>\n",
       "      <td>U.S. Representative</td>\n",
       "      <td>Yarmuth, John A.</td>\n",
       "      <td>D</td>\n",
       "      <td>@RepJohnYarmuth</td>\n",
       "      <td>NaN</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538</th>\n",
       "      <td>Alaska At-Large</td>\n",
       "      <td>U.S. Representative</td>\n",
       "      <td>Young, Don</td>\n",
       "      <td>R</td>\n",
       "      <td>@RepDonYoung</td>\n",
       "      <td>@repdonyoung</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539</th>\n",
       "      <td>Indiana</td>\n",
       "      <td>U.S. Senator</td>\n",
       "      <td>Young, Todd</td>\n",
       "      <td>R</td>\n",
       "      <td>@SenToddYoung</td>\n",
       "      <td>@sentoddyoung</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540</th>\n",
       "      <td>New York 1st District</td>\n",
       "      <td>U.S. Representative</td>\n",
       "      <td>Zeldin, Lee</td>\n",
       "      <td>R</td>\n",
       "      <td>@RepLeeZeldin</td>\n",
       "      <td>@leezeldin</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>541 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            State   Member of Congress              Name  \\\n",
       "0    North Carolina 12th District  U.S. Representative       Adams, Alma   \n",
       "1            Alabama 4th District  U.S. Representative  Aderholt, Robert   \n",
       "2        California 31st District  U.S. Representative     Aguilar, Pete   \n",
       "3           Georgia 12th District  U.S. Representative       Allen, Rick   \n",
       "4             Texas 32nd District  U.S. Representative     Allred, Colin   \n",
       "..                            ...                  ...               ...   \n",
       "536                        Oregon         U.S. Senator        Wyden, Ron   \n",
       "537         Kentucky 3rd District  U.S. Representative  Yarmuth, John A.   \n",
       "538               Alaska At-Large  U.S. Representative        Young, Don   \n",
       "539                       Indiana         U.S. Senator       Young, Todd   \n",
       "540         New York 1st District  U.S. Representative       Zeldin, Lee   \n",
       "\n",
       "    Party           Twitter         Instagram Facebook  \n",
       "0       D         @RepAdams         @repadams        x  \n",
       "1       R  @Robert_Aderholt  @robert_aderholt        x  \n",
       "2       D   @RepPeteAguilar  @rep.peteaguilar        x  \n",
       "3       R     @RepRickAllen    @rep_rickallen        x  \n",
       "4       D   @RepColinAllred   @repcolinallred        x  \n",
       "..    ...               ...               ...      ...  \n",
       "536     D         @RonWyden         @ronwyden        x  \n",
       "537     D   @RepJohnYarmuth               NaN        x  \n",
       "538     R      @RepDonYoung      @repdonyoung        x  \n",
       "539     R     @SenToddYoung     @sentoddyoung        x  \n",
       "540     R     @RepLeeZeldin        @leezeldin        x  \n",
       "\n",
       "[541 rows x 7 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_members_congress_df = pd.read_csv('../data/eeuu_member_of_congress.csv', sep=';')\n",
    "list_members_congress_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4697/629263200.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  list_members_congress_df['Twitter'] = list_members_congress_df['Twitter'].apply(lambda x: x.replace('@', ''))\n"
     ]
    }
   ],
   "source": [
    "list_members_congress_df = list_members_congress_df.dropna(subset = ['Party', 'Twitter'])\n",
    "list_members_congress_df['Twitter'] = list_members_congress_df['Twitter'].apply(lambda x: x.replace('@', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############# Scraping RepAdams timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping Robert_Aderholt timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping RepPeteAguilar timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping RepRickAllen timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping RepColinAllred timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping MarkAmodeiNV2 timeline #############\n",
      "############# Scraping SenAngusKing timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping RepArmstrongND timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping JodeyArrington timeline #############\n",
      "############# Scraping JakeAuch timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping RepCindyAxne timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping RepBrianBabin timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping RepDonBacon timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping RepJimBaird timeline #############\n",
      "############# Scraping RepBalderson timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping SenatorBaldwin timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping Jim_Banks timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping RepAndyBarr timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping Nanette4CA timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping SenJohnBarrasso timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping RepKarenBass timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping RepBeatty timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping MichaelBennet timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping RepBentz timeline #############\n",
      "############# Scraping RepBera timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping JackBergman_MI1 timeline #############\n",
      "############# Scraping RepDonBeyer timeline #############\n",
      "############# Scraping stephaniebice timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping AndyBiggs4AZ timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping RepGusBilirakis timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping SanfordBishop timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping jdanbishop timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping MarshaBlackburn timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping repblumenauer timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping SenBlumenthal timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping LisaBRochester timeline #############\n",
      "############# Scraping RoyBlunt timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping laurenboebert timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping RepBonamici timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping CoryBooker timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping JohnBoozman timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping RepBost timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping RepBourdeaux timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping JamaalBowmanNY timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping CongBoyle timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping RepKevinBrady timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping Braun4Indiana timeline #############\n",
      "############# Scraping RepMoBrooks timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping RepAnthonyBrown timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping SenSherrodBrown timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping ShontelMBrown timeline #############\n",
      "############# Scraping RepBrownley timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping VernBuchanan timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping RepKenBuck timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping RepLarryBucshon timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping BuddforCongress timeline #############\n",
      "############# Scraping RepTimBurchett timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping michaelcburgess timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping SenatorBurr timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping CoriBush timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping RepCheri timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping GKButterfield timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping KenCalvert timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping Kat_Cammack timeline #############\n",
      "############# Scraping SenatorCantwell timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping CarbajalSalud timeline #############\n",
      "############# Scraping RepCardenas timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping SenatorCardin timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping MikeCareyOH15 timeline #############\n",
      "############# Scraping RepJerryCarl timeline #############\n",
      "############# Scraping SenatorCarper timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping RepAndreCarson timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping RepBuddyCarter timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping JudgeCarter timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping RepCartwright timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping RepEdCase timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping SenBobCasey timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping BillCassidy timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping RepCasten timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping USRepKCastor timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping JoaquinCastrotx timeline #############\n",
      "############# Scraping CawthornforNC timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping RepSteveChabot timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping Liz_Cheney timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping CongresswomanSC timeline #############\n",
      "############# Scraping RepJudyChu timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping RepCicilline timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping RepKClark timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping RepYvetteClarke timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping repcleaver timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping RepBenCline timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping RepCloudTX timeline #############\n",
      "############# Scraping WhipClyburn timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping RepCohen timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping TomColeOK04 timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping SenatorCollins timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping JamesComer timeline #############\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scanned 1000 tweets\n",
      "############# Scraping GerryConnolly timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping SenCoonsOffice timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping repjimcooper timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping JohnCornyn timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping RepLouCorrea timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping CatherineForNV timeline #############\n",
      "Twitter API returned a 404 (Not Found), Sorry, that page does not exist.\n",
      "Skipping...\n",
      "############# Scraping RepJimCosta timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping SenTomCotton timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping RepJoeCourtney timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping RepAngieCraig timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping SenKevinCramer timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping MikeCrapo timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping RepRickCrawford timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping RepDanCrenshaw timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping CharlieCrist timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping RepJasonCrow timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping SenTedCruz timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping RepCuellar timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping RepJohnCurtis timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping SteveDaines timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping sharicedavids timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping WarrenDavidson timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping RepDannyDavis timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping RodneyDavis timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping RepDean timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping RepPeterDeFazio timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping RepDianaDeGette timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping rosadelauro timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping RepDelBene timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping RepDelgado timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping Val_Demings timeline #############\n",
      "Twitter API returned a 404 (Not Found), Sorry, that page does not exist.\n",
      "Skipping...\n",
      "############# Scraping RepDeSaulnier timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping DesJarlaisTN04 timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping RepTedDeutch timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping MarioDB timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping RepDebDingell timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping RepLloydDoggett timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping ByronDonalds timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping USRepMikeDoyle timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping RepJeffDuncan timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping DrNealDunnFL2 timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping SenatorDurbin timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping JakeEllzey timeline #############\n",
      "############# Scraping RepTomEmmer timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping RepEscobar timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping RepAnnaEshoo timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping EspaillatNY timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping RepRonEstes timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping RepDwightEvans timeline #############\n",
      "############# Scraping FallonForTexas timeline #############\n",
      "############# Scraping RandyFeenstra timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping SenFeinstein timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping DrewFergusonGA timeline #############\n",
      "############# Scraping TeresaForNM timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping FischbachMN7 timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping SenatorFischer timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping FitzgeraldForWI timeline #############\n",
      "############# Scraping RepBrianFitz timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping RepChuck timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping RepFletcher timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping JeffFortenberry timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping RepBillFoster timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping virginiafoxx timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping RepLoisFrankel timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping ScottFranklinFL timeline #############\n",
      "############# Scraping RepRussFulcher timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping MattGaetz timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping MikeforWI timeline #############\n",
      "############# Scraping RepRubenGallego timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping RepGaramendi timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping RepChuyGarcia timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping MikeGarcia2020 timeline #############\n",
      "Twitter API returned a 404 (Not Found), Sorry, that page does not exist.\n",
      "Skipping...\n",
      "############# Scraping RepSylviaGarcia timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping RepBobGibbs timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping SenGillibrand timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping RepCarlos timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping replouiegohmert timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping RepGolden timeline #############\n",
      "############# Scraping RepJimmyGomez timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping TonyGonzales4TX timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping Jenniffer2012 timeline #############\n",
      "Twitter API returned a 401 (Unauthorized), An error occurred processing your request.\n",
      "Skipping...\n",
      "############# Scraping RepAGonzalez timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping RepGonzalez timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping GoodForCongress timeline #############\n",
      "############# Scraping Lancegooden timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping RepGosar timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping JoshGottheimer timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping LindsayGrahamSC timeline #############\n",
      "############# Scraping RepKayGranger timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping ChuckGrassley timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "Scanned 3000 tweets\n",
      "############# Scraping RepGarretGraves timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping RepSamGraves timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping RepAlGreen timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############# Scraping RepMarkGreen timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "Scanned 3000 tweets\n",
      "############# Scraping mtgreenee timeline #############\n",
      "Twitter API returned a 401 (Unauthorized), An error occurred processing your request.\n",
      "Skipping...\n",
      "############# Scraping RepMGriffith timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping RepRaulGrijalva timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping RepGrothman timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping RepMichaelGuest timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping RepGuthrie timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping RepHagedorn timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping BillHagertyTN timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping RepJoshHarder timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping RepAndyHarrisMD timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping DHarshbargerTN1 timeline #############\n",
      "############# Scraping RepHartzler timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping Maggie_Hassan timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping HawleyMO timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping RepJahanaHayes timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping MartinHeinrich timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping RepKevinHern timeline #############\n",
      "############# Scraping Yvette4congress timeline #############\n",
      "############# Scraping HerreraBeutler timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping CongressmanHice timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping SenatorHick timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping RepBrianHiggins timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping CaptClayHIggins timeline #############\n",
      "############# Scraping RepFrenchHill timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping jahimes timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping RepAshleyHinson timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping maziehirono timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping SenJohnHoeven timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping VoteForTrey timeline #############\n",
      "############# Scraping RepHorsford timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping RepHoulahan timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping LeaderHoyer timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping RepRichHudson timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping RepHuffman timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping RepHuizenga timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping SenHydeSmith timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping InhofePress timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping DarrellIssa timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping JacksonLeeTX18 timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping RonnyJacksonTX timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping jacobsny27 timeline #############\n",
      "Twitter API returned a 404 (Not Found), Sorry, that page does not exist.\n",
      "Skipping...\n",
      "############# Scraping SaraJacobsCA timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping PramilaJayapal timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping RepJeffries timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping RepBillJohnson timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping RepDustyJohnson timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping RepEBJ timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping RepHankJohnson timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping RepMikeJohnson timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping SenRonJohnson timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping MondaireJones timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping SenJoniErnst timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "Scanned 3000 tweets\n",
      "############# Scraping Jim_Jordan timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping RepDaveJoyce timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping RepJohnJoyce timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping kaikahele timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping timkaine timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping RepMarcyKaptur timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping RepJohnKatko timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping USRepKeating timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping RepFredKelle timeline #############\n",
      "Twitter API returned a 404 (Not Found), Sorry, that page does not exist.\n",
      "Skipping...\n",
      "############# Scraping SenMarkKelly timeline #############\n",
      "############# Scraping MikeKellyforPA timeline #############\n",
      "############# Scraping RepRobinKelly timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping RepTrentKelly timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping JohnKennedyLA timeline #############\n",
      "############# Scraping RoKhannaUSA timeline #############\n",
      "############# Scraping RepDanKildee timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping RepDerekKilmer timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping RepAndyKimNJ timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping YoungKimCA timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping RepRonKind timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping RepKinzinger timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping RepKirkPatrick timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping amyklobuchar timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "Scanned 3000 tweets\n",
      "############# Scraping RajaForCongress timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping RepAnnieKuster timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping DavidKustoff timeline #############\n",
      "############# Scraping ElectLaHood timeline #############\n",
      "Twitter API returned a 404 (Not Found), Sorry, that page does not exist.\n",
      "Skipping...\n",
      "############# Scraping RepLaMalfa timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping RepConorLamb timeline #############\n",
      "############# Scraping RepDLamborn timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping jimlangevin timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping SenatorLankford timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping RepRickLarsen timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping RepJohnLarson timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping boblatta timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping JakeLaTurner timeline #############\n",
      "############# Scraping RepLawrence timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping AlLawsonJr timeline #############\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############# Scraping  SenatorLeahy timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping RepBarbaraLee timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping SenMikeLee timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping RepSusieLee timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping RepDLesko timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "Scanned 3000 tweets\n",
      "############# Scraping jbletlow timeline #############\n",
      "############# Scraping RepAndyLevin timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping RepMikeLevin timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping RepTedLieu timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping RepZoeLofgren timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping USRepLong timeline #############\n",
      "############# Scraping RepLoudermilk timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping RepLowenthal timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping RepFrankLucas timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping RepBlaine timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping SenatorLujan timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping SenLummis timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping RepElaineLuria timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping RepStephenLynch timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping NancyMace timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping RepMalinowski timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping Nmalliotakis timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping RepMaloney timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping RepSeanMaloney timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping Sen_JoeManchin timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping TraceyMannKS timeline #############\n",
      "############# Scraping KathyManningNC timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping SenMarkey timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping RogerMarshallMD timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping RepThomasMassie timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping BrianMastFL timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping DorisMatsui timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping RepLucyMcBath timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping GOPLeader timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping RepMcCaul timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping LisaForCongress timeline #############\n",
      "############# Scraping RepMcClintock timeline #############\n",
      "############# Scraping BettyMcCollum04 timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping McConnellPress timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping Donald_McEachin timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping RepMcGovern timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping PatrickMcHenry timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping RepMcKinley timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping cathymcmorris timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping RepMcNerney timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping RepGregoryMeeks timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping VoteMeijer timeline #############\n",
      "############# Scraping SenatorMenendez timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping RepGraceMeng timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping SenJeffMerkley timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping RepMeuser timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping Mfume4Congress timeline #############\n",
      "############# Scraping RepMMM timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping RepCarolMiller timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping RepMaryMiller timeline #############\n",
      "############# Scraping RepMoolenaar timeline #############\n",
      "############# Scraping RepAlexMooney timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping SenCapito timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping RepBarryMoore timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping RepBlakeMoore timeline #############\n",
      "############# Scraping RepGwenMoore timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping JerryMoran timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping RepJoeMorelle timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping teammoulton timeline #############\n",
      "Twitter API returned a 404 (Not Found), Sorry, that page does not exist.\n",
      "Skipping...\n",
      "############# Scraping RepMrvan timeline #############\n",
      "############# Scraping RepMullin timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping lisamurkowski timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping ChrisMurphyCT timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping RepGregMurphy timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping SMurphyCongress timeline #############\n",
      "Twitter API returned a 404 (Not Found), Sorry, that page does not exist.\n",
      "Skipping...\n",
      "############# Scraping PattyMurray timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping RepJerryNadler timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping gracenapolitano timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping RepRichardNeal timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping RepJoeNeguse timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping SheriffTNehls timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping RepNewhouse timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping RepMarieNewman timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping DonNorcross4NJ timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping RepRalphNorman timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping EleanorNorton timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping TomOHalleran timeline #############\n",
      "############# Scraping JayObernolte timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping RepAOC timeline #############\n",
      "############# Scraping IlhanMN timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping ossoff timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping BurgessOwens timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping KamalaHarris timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping CongPalazzo timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping FrankPallone timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping USRepGaryPalmer timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping JimmyPanetta timeline #############\n",
      "############# Scraping RepChrisPappas timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping BillPascrell timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping RandPaul timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping RepDonaldPayne timeline #############\n",
      "Scanned 1000 tweets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scanned 2000 tweets\n",
      "############# Scraping SpeakerPelosi timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping RepGregPence timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping RepPerlmutter timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping RepScottPerry timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping SenGaryPeters timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping RepScottPeters timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping AugustPfluger timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping RepDeanPhillips timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping chelliepingree timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping StaceyPlaskett timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping repmarkpocan timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping RepKatiePorter timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping senrobportman timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping congbillposey timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping RepPressley timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping RepDavidEPrice timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping RepMikeQuigley timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping RepAmata timeline #############\n",
      "############# Scraping Jamie_Raskin timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping SenJackReed timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping RepTomReed timeline #############\n",
      "Twitter API returned a 404 (Not Found), Sorry, that page does not exist.\n",
      "Skipping...\n",
      "############# Scraping GReschenthaler timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping RepKathleenRice timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping RepTomRice timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping RepRichmond timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping SenatorRisch timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping RepHalRogers timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping RepMikeRogers timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping SenatorRomney timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping RepJohnRose timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping SenJackyRosen timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping MattForMontana timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping DeborahRossNC timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping SenatorRounds timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping RepDavidRouzer timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping RepChipRoy timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping RepRoybalAllard timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping marcorubio timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping RepRaulRuizMD timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping Call_Me_Dutch timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping RepBobbyRush timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping JRutherfordFL timeline #############\n",
      "############# Scraping RepTimRyan timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping Kilili_Sablan timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping MaElviraSalazar timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping GuamCongressman timeline #############\n",
      "############# Scraping RepLindaSanchez timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping SenSanders timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping RepSarbanes timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping SenSasse timeline #############\n",
      "############# Scraping SteveScalise timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping RepMGS timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping janschakowsky timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping SenBrianSchatz timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping RepAdamSchiff timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping RepSchneider timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping RepSchrader timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping RepKimSchrier timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping SenSchumer timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping RepDavid timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping AustinScottGA08 timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping repdavidscott timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping ScottforFlorida timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping BobbyScott timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping SenatorTimScott timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping SessionsTX17 timeline #############\n",
      "############# Scraping RepTerriSewell timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping SenatorShaheen timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping SenShelby timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping BradSherman timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping RepSherrill timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping CongMikeSimpson timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping SenatorSinema timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping RepSires timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping RepSlotkin timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping RepAdamSmith timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping RepAdrianSmith timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping RepChrisSmith timeline #############\n",
      "Twitter API returned a 401 (Unauthorized), An error occurred processing your request.\n",
      "Skipping...\n",
      "############# Scraping RepJasonSmith timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping SenTinaSmith timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping RepLloyd timeline #############\n",
      "Twitter API returned a 401 (Unauthorized), An error occurred processing your request.\n",
      "Skipping...\n",
      "############# Scraping RepDarrenSoto timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping RepSpanberger timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping Victoria_Spartz timeline #############\n",
      "############# Scraping RepSpeier timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping SenStabenow timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping Rep_Stansbury timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping RepGregStanton timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping RepPeteStauber timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping MichelleSteelCA timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping RepStefanik timeline #############\n",
      "Scanned 1000 tweets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scanned 2000 tweets\n",
      "############# Scraping RepBryanSteil timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping RepGregSteube timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping RepHaleyStevens timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping RepChrisStewart timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping StricklandforWA timeline #############\n",
      "############# Scraping SenDanSullivan timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping Tom_Suozzi timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping RepSwalwell timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping RepMarkTakano timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping SenDuckworth timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping RepVanTaylor timeline #############\n",
      "############# Scraping claudiatenney timeline #############\n",
      "############# Scraping SenatorTester timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping BennieGThompson timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping CongressmanGT timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping RepThompson timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping SenJohnThune timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping TomTiffanyWI timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping SenThomTillis timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping RepTimmons timeline #############\n",
      "############# Scraping repdinatitus timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping RepRashida timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping RepPaulTonko timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping SenToomey timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping NormaJTorres timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping RitchieTorres timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping RepLoriTrahan timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping RepDavidTrone timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping Ttuberville timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping RepMikeTurner timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping RepUnderwood timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping RepFredUpton timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping RepDavidValadao timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping JeffVanDrew timeline #############\n",
      "Twitter API returned a 401 (Unauthorized), An error occurred processing your request.\n",
      "Skipping...\n",
      "############# Scraping Bethvanduyne timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping ChrisVanHollen timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping RepJuanVargas timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping RepVeasey timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping RepFilemonVela timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping NydiaVelazquez timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping RepAnnWagner timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping RepWalberg timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping RepWalorski timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping RepMichaelWaltz timeline #############\n",
      "Twitter API returned a 404 (Not Found), Sorry, that page does not exist.\n",
      "Skipping...\n",
      "############# Scraping MarkWarner timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping ReverendWarnock timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping SenWarren timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping RepDWStweets timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping MaxineWaters timeline #############\n",
      "############# Scraping RepBonnie timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping TXRandy14 timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping RepWebster timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping PeterWelch timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping RepBradWenstrup timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping RepWesterman timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping RepWexton timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping SenWhitehouse timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping SenatorWicker timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping RepSusanWild timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping NikemaWilliams timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping RepRWilliams timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping RepWilson timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping RepJoeWilson timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping RobWittman timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping rep_stevewomack timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping RonWyden timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping RepJohnYarmuth timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping RepDonYoung timeline #############\n",
      "Scanned 1000 tweets\n",
      "############# Scraping SenToddYoung timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n",
      "############# Scraping RepLeeZeldin timeline #############\n",
      "Scanned 1000 tweets\n",
      "Scanned 2000 tweets\n"
     ]
    }
   ],
   "source": [
    "fields = ['id', 'user', 'created_at', 'full_text', 'lang', 'label', 'retweet_count', 'favorite_count']\n",
    "max_id = None\n",
    "for index, row in list_members_congress_df.iterrows():\n",
    "    df_output = pd.DataFrame(columns = fields)\n",
    "    while True:\n",
    "        try:\n",
    "            name_user = row['Twitter']\n",
    "            print(f'############# Scraping {name_user} timeline #############')\n",
    "            for idx, tweet in enumerate(timeline(name_user, max_id)):\n",
    "                if (idx+1) % 1000 == 0:\n",
    "                    print(f'Scanned {idx+1} tweets')\n",
    "                sub = {k: v for k, v in tweet.items() if k in fields}\n",
    "                sub['user'] = sub['user']['id']\n",
    "                sub['label'] = row['Party']\n",
    "                df_output = df_output.append(sub, ignore_index=True)\n",
    "                max_id = sub['id']\n",
    "            max_id = None\n",
    "            break\n",
    "        except TwythonRateLimitError as e:\n",
    "            sleep_until(e.retry_after) # sleep until the given date\n",
    "        except TwythonError as e:\n",
    "            # I *think* this is caused by protected profiles. \n",
    "            # I can read some user profile info, but not the timeline\n",
    "            print(e)\n",
    "            print(\"Skipping...\")\n",
    "            break\n",
    "    df_output.rename(columns={'full_text':'text'}).to_csv(f'../data/{name_user}.csv', sep='|', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
